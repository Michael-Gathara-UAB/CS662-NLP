{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam CS/INFO 662/762 Fall 2023\n",
    "CS/INFO 762: 100 points ; CS/INFO 662  90 points\n",
    "\n",
    "### <font color='red'>Due Dec 9th, 11:59am</font> - Submission via Canvas (.ipynb file)\n",
    "\n",
    "## STUDENT NAME: <font color='red'>MICHAEL GATHARA</font>\n",
    "\n",
    "\n",
    "* Question 1a: Medical Mention Normalization with SAPBERT (PhD Students must include one graph feature) - 35/25 points\n",
    "* Question 1b: Compute Recall - 15 points\n",
    "* Question 1c: Random Forest: Feature Importance - 10 points\n",
    "* Question 2: Language Model Questions (Long Written Answer) - 40 points\n",
    "\n",
    "<font color='red'>As always WORK ON YOUR OWN for this final exam. Like last year, the final exam will be run through plagarism detection software. You may email me for clarification, but don't post on Stack Overflow, Quota, Reddit, etc..  You MAY use ChatGPT for ANY question, but the usual rules for citation and prompt inclusion in your answer apply.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting obonet\n",
      "  Downloading obonet-1.0.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Installing collected packages: networkx, obonet\n",
      "Successfully installed networkx-3.2.1 obonet-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting py-rouge\n",
      "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-rouge\n",
      "Successfully installed py-rouge-1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting node2vec\n",
      "  Downloading node2vec-0.4.6-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from node2vec) (4.65.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from node2vec) (1.22.3)\n",
      "Collecting networkx<3.0,>=2.5\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gensim<5.0.0,>=4.1.2 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from node2vec) (4.3.2)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from node2vec) (1.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.10.1)\n",
      "Installing collected packages: networkx, node2vec\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "Successfully installed networkx-2.8.8 node2vec-0.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from rouge-score) (2.0.0)\n",
      "Requirement already satisfied: nltk in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from rouge-score) (1.22.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: joblib in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from nltk->rouge-score) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from nltk->rouge-score) (2023.3.23)\n",
      "Requirement already satisfied: click in /data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=2376b2f15033117f5d6a221c885b824f1ce4b4dcd15883a8619a5a4c031f3463\n",
      "  Stored in directory: /data/user/home/mikegtr/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If needed\n",
    "#!pip uninstall --yes flair\n",
    "%pip install obonet\n",
    "%pip install py-rouge\n",
    "%pip install node2vec\n",
    "%pip install rouge-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Ontology is currently size:11432 with 11462 edges\n",
      "Human Phenotype Ontology is currently size:17664 with 21975 edges\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import networkx\n",
    "import obonet\n",
    "import os\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import heapq\n",
    "import pandas as pd\n",
    "#import scispacy\n",
    "import spacy\n",
    "import numpy as np\n",
    "import torch\n",
    "from io import StringIO\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")  \n",
    "model = AutoModel.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\").cuda()\n",
    "\n",
    "do_url = 'https://raw.githubusercontent.com/DiseaseOntology/HumanDiseaseOntology/main/src/ontology/HumanDO.obo'\n",
    "hpo_url = 'http://purl.obolibrary.org/obo/hp.obo'\n",
    "do = obonet.read_obo(do_url)\n",
    "hpo = obonet.read_obo(hpo_url)\n",
    "print('Disease Ontology is currently size:'+str(len(do))+\" with \"+str(do.number_of_edges())+' edges')\n",
    "print('Human Phenotype Ontology is currently size:'+str(len(hpo))+\" with \"+str(hpo.number_of_edges())+' edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Concept Normalization\n",
    "This question requires you to write use the SAPBERT embeddings you are familiar with from assignment #2 to generate candidate concepts for each input medical mentions for a merged overlapping knowledge graph of both the Disease Ontology (DO) and Human Phenotyper Ontology (HPO). \n",
    "\n",
    "### Set Up Knowledge Graph and Corpus Preparation \n",
    "This code is provided to you and creates:\n",
    "* The merged knowledge graph (kgs) from the both Disease Ontology (DO) and the Human Phenotype Ontology (HPO) as a dataframe. You also have access to the original graphs in obo format to get graph features, for example you can use node2vec.\n",
    "* The input corpus and medical mentions (labelled data) as a dataframe, \"mention_mapping\". It is built from the input corpus and you can assume that NER has already been done to identify the mentions to map. They are in the \"mention\" column and the correct concept (CUI) it should be mapped to is in the \"CUI\" column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO Vocabulary: hpokg\n",
      "            HPOID       CUI  DOID                          HPO:Name DO:Name\n",
      "0      HP:0000001  C0444868  None                               All    None\n",
      "1      HP:0000002  C4025901  None        Abnormality of body height    None\n",
      "2      HP:0000003  C3714581  None      Multicystic kidney dysplasia    None\n",
      "3      HP:0000005  C1708511  None               Mode of inheritance    None\n",
      "4      HP:0000006  C0443147  None    Autosomal dominant inheritance    None\n",
      "...           ...       ...   ...                               ...     ...\n",
      "17659  HP:5201010      None  None  Microform cleft of the upper lip    None\n",
      "17660  HP:5201011      None  None      Complete bilateral cleft lip    None\n",
      "17661  HP:5201012      None  None    Incomplete bilateral cleft lip    None\n",
      "17662  HP:5201013      None  None     Microform bilateral cleft lip    None\n",
      "17663  HP:5201014      None  None    Asymmetric bilateral cleft lip    None\n",
      "\n",
      "[17664 rows x 5 columns]\n",
      "HPO and DO Joint Vocabulary:kgs\n",
      "            HPOID       CUI          DOID                  HPO:Name  \\\n",
      "9      HP:0000011  C0005697    DOID:12143        Neurogenic bladder   \n",
      "13     HP:0000015  C0156273    DOID:11353      Bladder diverticulum   \n",
      "20     HP:0000023  C0019294  DOID:0060320           Inguinal hernia   \n",
      "21     HP:0000024  C0033581    DOID:14654               Prostatitis   \n",
      "24     HP:0000027  C0004509    DOID:14227               Azoospermia   \n",
      "...           ...       ...           ...                       ...   \n",
      "16448  HP:0200018  C0155015    DOID:13910               Protanomaly   \n",
      "16451  HP:0200022  C0205770     DOID:2626  Choroid plexus papilloma   \n",
      "16452  HP:0200023  C0033117     DOID:9286                  Priapism   \n",
      "16480  HP:0200058  C0018923  DOID:0001816              Angiosarcoma   \n",
      "16532  HP:0200151  C1136033     DOID:3663    Cutaneous mastocytosis   \n",
      "\n",
      "                        DO:Name  \n",
      "9            neurogenic bladder  \n",
      "13         bladder diverticulum  \n",
      "20              inguinal hernia  \n",
      "21                  prostatitis  \n",
      "24                  azoospermia  \n",
      "...                         ...  \n",
      "16448       red color blindness  \n",
      "16451  choroid plexus papilloma  \n",
      "16452                  priapism  \n",
      "16480              angiosarcoma  \n",
      "16532    cutaneous mastocytosis  \n",
      "\n",
      "[970 rows x 5 columns]\n",
      "Input Corpus Mentions:mention_mapping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CUI</th>\n",
       "      <th>start1</th>\n",
       "      <th>stop1</th>\n",
       "      <th>start2</th>\n",
       "      <th>stop2</th>\n",
       "      <th>start3</th>\n",
       "      <th>stop3</th>\n",
       "      <th>mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N000</td>\n",
       "      <td>C0011854</td>\n",
       "      <td>248</td>\n",
       "      <td>283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>insulin dependent diabetes mellitus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N001</td>\n",
       "      <td>C4303631</td>\n",
       "      <td>298</td>\n",
       "      <td>327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a right above-knee amputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N003</td>\n",
       "      <td>C0085671</td>\n",
       "      <td>537</td>\n",
       "      <td>553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dressing changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N004</td>\n",
       "      <td>C0011079</td>\n",
       "      <td>558</td>\n",
       "      <td>569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debridement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N005</td>\n",
       "      <td>C0003232</td>\n",
       "      <td>611</td>\n",
       "      <td>622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>antibiotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>N139</td>\n",
       "      <td>C0442519</td>\n",
       "      <td>4695</td>\n",
       "      <td>4699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>N140</td>\n",
       "      <td>C0699203</td>\n",
       "      <td>4731</td>\n",
       "      <td>4737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>motrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>N141</td>\n",
       "      <td>C0593507</td>\n",
       "      <td>4740</td>\n",
       "      <td>4745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>N142</td>\n",
       "      <td>C0332575</td>\n",
       "      <td>4863</td>\n",
       "      <td>4870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>redness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>N143</td>\n",
       "      <td>C0205217</td>\n",
       "      <td>4853</td>\n",
       "      <td>4862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>increased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6684 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID       CUI  start1  stop1  start2  stop2  start3  stop3  \\\n",
       "0     N000  C0011854     248    283     NaN    NaN     NaN    NaN   \n",
       "1     N001  C4303631     298    327     NaN    NaN     NaN    NaN   \n",
       "2     N003  C0085671     537    553     NaN    NaN     NaN    NaN   \n",
       "3     N004  C0011079     558    569     NaN    NaN     NaN    NaN   \n",
       "4     N005  C0003232     611    622     NaN    NaN     NaN    NaN   \n",
       "...    ...       ...     ...    ...     ...    ...     ...    ...   \n",
       "6679  N139  C0442519    4695   4699     NaN    NaN     NaN    NaN   \n",
       "6680  N140  C0699203    4731   4737     NaN    NaN     NaN    NaN   \n",
       "6681  N141  C0593507    4740   4745     NaN    NaN     NaN    NaN   \n",
       "6682  N142  C0332575    4863   4870     NaN    NaN     NaN    NaN   \n",
       "6683  N143  C0205217    4853   4862     NaN    NaN     NaN    NaN   \n",
       "\n",
       "                                  mention  \n",
       "0     insulin dependent diabetes mellitus  \n",
       "1           a right above-knee amputation  \n",
       "2                        dressing changes  \n",
       "3                             debridement  \n",
       "4                             antibiotics  \n",
       "...                                   ...  \n",
       "6679                                 home  \n",
       "6680                               motrin  \n",
       "6681                                advil  \n",
       "6682                              redness  \n",
       "6683                            increased  \n",
       "\n",
       "[6684 rows x 9 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createIndex(graph,prefix):\n",
    "    id2cui = {}\n",
    "    cui2id = {}\n",
    "    id_to_xref = {id_: data.get('xref') for id_, data in graph.nodes(data=True)}\n",
    "    for graph_id,xrefs in id_to_xref.items():\n",
    "        if(xrefs is None):\n",
    "            cui = None\n",
    "        else:\n",
    "            cui = next((x for x in xrefs if x.startswith(prefix)),None)\n",
    "            if(cui is not None):\n",
    "                cui = cui.replace(prefix,'')\n",
    "        id2cui[graph_id]=cui\n",
    "        if(cui is not None):\n",
    "            cui2id[cui]=graph_id\n",
    "    return(id2cui,cui2id)\n",
    "\n",
    "\n",
    "def convertCui2Doid(cui):\n",
    "    if cui in cui2do:\n",
    "        return cui2do[cui]\n",
    "    return None\n",
    "\n",
    "def hpoId2Name(oboid):\n",
    "    return hpoid_to_name[oboid]\n",
    "\n",
    "def doId2Name(oboid):\n",
    "    if(oboid is None):\n",
    "        return None\n",
    "    if (doid_to_name[oboid]):\n",
    "        return doid_to_name[oboid]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mentions(filename,bardoc):\n",
    "    all_mentions = []\n",
    "    with open(filename, 'r') as file: \n",
    "        textdoc = file.read()\n",
    "        for line in bardoc.splitlines():\n",
    "            #print(line)\n",
    "            start = int(line.split(\"||\")[2])\n",
    "            stop = int(line.split(\"||\")[3])\n",
    "            mention = textdoc[start:stop]\n",
    "            if(not line.endswith(\"||||||\")):\n",
    "                start = int(line.split(\"||\")[4])\n",
    "                stop = int(line.split(\"||\")[5])\n",
    "                extramention = textdoc[start:stop]\n",
    "                mention = mention+' '+extramention\n",
    "                if(not line.endswith(\"||||\")):\n",
    "                    start = int(line.split(\"||\")[6])\n",
    "                    stop = int(line.split(\"||\")[7])\n",
    "                    extramention = textdoc[start:stop]\n",
    "                    mention = mention+' '+extramention\n",
    "            #print(mention)\n",
    "            all_mentions.append(mention)\n",
    "    return all_mentions\n",
    "\n",
    "def read_files(directory):\n",
    "    all_data = []\n",
    "    for file in os.listdir(directory):\n",
    "        #print(file)\n",
    "        if file.endswith(\".norm\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, 'r') as file:\n",
    "                csv_string = file.read()\n",
    "            #normed = [line+\"||||\" for line in csv_string.splitlines() if line.count('|')==6]\n",
    "            normed = [line if line.count('|') == 14 else (line+\"||||\" if line.count('|') == 10 else line+\"||||||||\") for line in csv_string.splitlines()]\n",
    "            clean = '\\n'.join(normed)\n",
    "            note_file = (str(file.name).replace(\"train_norm\",\"train_note\").replace(\"norm\",\"txt\"))\n",
    "            mentions = get_mentions(note_file,clean)\n",
    "            df = pd.read_csv(StringIO(clean),engine='python',names=['ID', 'CUI', 'start1', 'stop1','start2','stop2','start3','stop3'],sep=\"\\|\\|\")\n",
    "            df['mention']=mentions\n",
    "        all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "hpo2cui,cui2hpo = createIndex(hpo,'UMLS:')\n",
    "do2cui,cui2do = createIndex(do,'UMLS_CUI:')\n",
    "id_to_cui = {**hpo2cui, **do2cui}\n",
    "\n",
    "hpoid_to_name = {id_: data.get('name') for id_, data in hpo.nodes(data=True)}\n",
    "doid_to_name = {id_: data.get('name') for id_, data in do.nodes(data=True)}\n",
    "\n",
    "df = pd.DataFrame(list(hpo2cui.items()))\n",
    "df.columns=['HPOID','CUI']\n",
    "df['DOID'] = df['CUI'].apply(convertCui2Doid)\n",
    "df['HPO:Name'] = df['HPOID'].apply(hpoId2Name)\n",
    "df['DO:Name'] = df['DOID'].apply(doId2Name)\n",
    "hpokg = df.copy()\n",
    "print(\"HPO Vocabulary: hpokg\")\n",
    "print(hpokg)\n",
    "kgs = df.mask(df.eq('None')).dropna()\n",
    "\n",
    "# Graph properties that may be useful\n",
    "id_to_isa = {id_: data.get('is_a') for id_, data in hpo.nodes(data=True)}\n",
    "id_to_xref = {id_: data.get('xref') for id_, data in do.nodes(data=True)}\n",
    "result = next(iter(id_to_xref.values()))   \n",
    "\n",
    "print(\"HPO and DO Joint Vocabulary:kgs\")\n",
    "print(kgs)\n",
    "mention_mapping = read_files(\"train/train_norm/\")\n",
    "print(\"Input Corpus Mentions:mention_mapping\")\n",
    "mention_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1a: Generation of Candidate Concepts and their Features (35 points PhD/ 25 points MS)\n",
    "\n",
    "\n",
    "#### Write code to find the best N candidate concepts for the mention using SAPBERT in the small (for final exam performance purposes) merged kgs vocabularuy.\n",
    "\n",
    "The signature of the function should look something like this:\n",
    "``` \n",
    "def getCandidates(mention_embeddings, vocabulary_embeddings, max_candidates):\n",
    "```\n",
    "* mention_embeddings would be SAPBERT embeddings of the mentions\n",
    "* vocabulary_embeddings would be SAPBERT embeddings of the kgs vocabulary. You generate them using just DO concept text, just HPO concept text or perform a function to aggregate them.\n",
    "* max_candidates (max candidates to return from kgs)\n",
    "\n",
    "This function returns a list of the best N matches between the mention and the target merged knowledge graph based on feature similarity between the input node and the target node. Each match in the list is a tuple can contain any elements you need, but it should at least contain\n",
    " * a reference to the target concept, ie) row index|vocabulary_id\n",
    " * score (optional) or anything else you think you need\n",
    " \n",
    " \n",
    "#### Write code to get a set of features for each candidate concepts that can be used for ranking the top N concepts to pick the most correct concept\n",
    "The getFeatures function should generate features for an input mention text and one possible candidate mapping.\n",
    "```\n",
    "def getFeatures(mention_text, candidate_tuple_from_getCandidates)\n",
    "```\n",
    "These features will be used in Part 1b) to generate training data for a machine learning ranking algorithm.\n",
    "\n",
    "Masters student need at least 2 features in their getFeatures code, some examples of lexical features include:\n",
    "* counts of matching words or characters\n",
    "* longest common subsequence (RougeL)\n",
    "* ngram overlap, etc...\n",
    "\n",
    "PhD Students will need an additional graph-based feature using relations in the ontology or ontology node vector representations such as node2vec. For example, one relevant feature may be checking the similarity of the input node to the parent node of the target. They can also be generated per random-walks like node2vec.\n",
    "\n",
    "\n",
    "Hints:\n",
    " * stop words, stemming, lemmatizationm, headword matching are nice but not required for this tiny (mostly matching) gold data set\n",
    " * my advice is to do the minimal amount of work and come back later if you want to add more features\n",
    " * you may use ANY additional libraries as need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 23 µs, total: 23 µs\n",
      "Wall time: 27.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "\n",
    "# Candidate Generation Code\n",
    "# def getCandidates(mention_embeddings, vocabulary_embeddings, max_candidates):\n",
    "#     \"\"\"\n",
    "#     * mention_embeddings would be SAPBERT embeddings of the mentions\n",
    "#     * vocabulary_embeddings would be SAPBERT embeddings of the kgs vocabulary. You generate them using just DO concept text, just HPO concept text or perform a function to aggregate them.\n",
    "#     * max_candidates (max candidates to return from kgs)\n",
    "#     \"\"\"\n",
    "#     # Initialize an empty list to store the candidate concepts\n",
    "#     candidates = []\n",
    "\n",
    "#     # Compute cosine similarity between each mention embedding and all vocabulary embeddings\n",
    "#     # This will result in a matrix of similarity scores\n",
    "#     similarity_scores = cosine_similarity(mention_embeddings, vocabulary_embeddings)\n",
    "\n",
    "#     # Iterate over each mention\n",
    "#     for mention_index, scores in enumerate(similarity_scores):\n",
    "#         # Sort the scores in descending order and get the indices (which correspond to vocabulary IDs)\n",
    "#         ranked_vocabulary_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "#         # Select the top N candidates based on max_candidates\n",
    "#         top_candidates = ranked_vocabulary_indices[:max_candidates]\n",
    "\n",
    "#         # Format and add the candidates for this mention to the list\n",
    "#         # Including the vocabulary index (or ID) and the corresponding similarity score\n",
    "#         mention_candidates = [(vocab_index, scores[vocab_index]) for vocab_index in top_candidates]\n",
    "#         candidates.append(mention_candidates)\n",
    "\n",
    "#     return candidates[0]\n",
    "# def getCandidates(mention_embedding, vocabulary_embeddings, vocabulary_terms, max_candidates):\n",
    "#     # Compute cosine similarity between mention embedding and all vocabulary embeddings\n",
    "#     similarity_scores = cosine_similarity([mention_embedding], vocabulary_embeddings)[0]\n",
    "#     print(\"Here\")\n",
    "\n",
    "#     # Get the indices of the top N scoring terms\n",
    "#     top_candidate_indices = np.argsort(similarity_scores)[::-1][:max_candidates]\n",
    "#     print(\"There\")\n",
    "\n",
    "#     # Retrieve the top N candidates with their text, index, and score\n",
    "#     candidates = [(vocabulary_terms[i], i, similarity_scores[i]) for i in top_candidate_indices]\n",
    "#     print(\"Almost out\")\n",
    "    \n",
    "#     return candidates\n",
    "# def getCandidates(mention_embedding, vocabulary_embeddings, vocabulary_terms, max_candidates):\n",
    "#     # Ensure mention_embedding is 2D\n",
    "#     if mention_embedding.ndim == 1:\n",
    "#         mention_embedding = mention_embedding.reshape(1, -1)\n",
    "#     elif mention_embedding.ndim > 2:\n",
    "#         raise ValueError(f\"mention_embedding should be 2D, but got shape {mention_embedding.shape}\")\n",
    "\n",
    "#     # Compute cosine similarity between mention embedding and all vocabulary embeddings\n",
    "#     similarity_scores = cosine_similarity(mention_embedding, vocabulary_embeddings)[0]\n",
    "\n",
    "#     # Get the indices of the top N scoring terms\n",
    "#     top_candidate_indices = np.argsort(similarity_scores)[::-1][:max_candidates]\n",
    "\n",
    "#     # Retrieve the top N candidates with their text, index, and score\n",
    "#     candidates = [(vocabulary_terms[i], i, similarity_scores[i]) for i in top_candidate_indices]\n",
    "\n",
    "#     return candidates\n",
    "def getCandidates(mention_embedding, vocabulary_embeddings, vocabulary_ids, max_candidates, id_to_cui):\n",
    "    # Compute cosine similarity between mention embedding and all vocabulary embeddings\n",
    "    similarity_scores = cosine_similarity([mention_embedding], vocabulary_embeddings)[0]\n",
    "\n",
    "    # Get the indices of the top N scoring terms\n",
    "    top_candidate_indices = np.argsort(similarity_scores)[::-1][:max_candidates]\n",
    "\n",
    "    # Retrieve the top N candidates with their CUIs and similarity scores\n",
    "    candidates = [(id_to_cui[vocabulary_ids[i]], i, similarity_scores[i]) for i in top_candidate_indices if vocabulary_ids[i] in id_to_cui]\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def getFeatures(mention_text, candidate_tuple_from_getCandidates):\n",
    "    # Unpack the candidate tuple\n",
    "    candidate_id, similarity_score, _ = candidate_tuple_from_getCandidates\n",
    "\n",
    "    # Feature 1: Length of candidate concept (simple example)\n",
    "    length_feature = len(candidate_id)\n",
    "\n",
    "    # Feature 2: Similarity of mention text to candidate concept (using SequenceMatcher for simplicity)\n",
    "    sm = SequenceMatcher(None, mention_text, candidate_id)\n",
    "    text_similarity_feature = sm.ratio()\n",
    "\n",
    "    # Graph-based Feature (for PhD students): This is a placeholder.\n",
    "    # You'll need to replace it with an actual graph-based feature calculation.\n",
    "    # For example, it could be the similarity between the mention and the parent node of the target in an ontology.\n",
    "    graph_based_feature = np.random.random()  # Placeholder - replace with actual feature calculation\n",
    "\n",
    "    # Compile features into a vector\n",
    "    feature_vector = [length_feature, text_similarity_feature, graph_based_feature]\n",
    "\n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1b: Compute Recall@3 and Generate Data for ML Algorithm in Part 1c (15 points)\n",
    " * Use your function in Part 1a) to generate 3 candidates for every mention and compute recall at n=3 candidates (For each mention, what is the fraction of times that the getCandidates returned the correct concept (CUI)?). Your re-ranking algorithm will not be able to do better than this. (5 points)\n",
    " * Many mentions represent concepts not included in our small merged kgs. Despite this, your recall performance may still not match your expectations using just SAPBERT embeddings. Explain why this might be (5 points).  \n",
    " * Create a labelled candidate ranking data set (5 points). For each mention, there will be 3 examples of which only 1 will have the correct CUI. Each example will have features (X) from part 1a and a label (Y). The label will be 1 if the features are sourced from the correct CUI and 0 if not. Use your getFeatures function to populate X. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(mention_text):\n",
    "    # Tokenize the mention text\n",
    "    inputs = tokenizer(mention_text, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "    \n",
    "    # Get the embeddings from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # For SapBERT, the pooled output is typically at outputs.pooler_output or outputs.last_hidden_state.mean(dim=1)\n",
    "    # You will need to confirm the correct output for your model version\n",
    "    embeddings = outputs.pooler_output if hasattr(outputs, 'pooler_output') else outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    # Move embeddings to CPU and convert to numpy if necessary\n",
    "#     embeddings = embeddings.cpu().numpy()\n",
    "    embeddings = embeddings.reshape(1, -1)\n",
    "    \n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "mention_mapping['mention_embedding'] = mention_mapping['mention'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a6b7db308043f1915e69e3c8f0a759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming 'do' and 'hpo' are networkx graphs loaded from OBO files\n",
    "do_terms = list(do.nodes)\n",
    "hpo_terms = list(hpo.nodes)\n",
    "# # Combine the names or descriptions from both ontologies into one list\n",
    "# do_terms = [do.nodes[node]['name'] for node in do.nodes]\n",
    "# hpo_terms = [hpo.nodes[node]['name'] for node in hpo.nodes]\n",
    "\n",
    "# # Now we combine the terms from DO and HPO into one list\n",
    "# kgs_terms = do_terms + hpo_terms\n",
    "\n",
    "# Combine the terms from DO and HPO into one list\n",
    "kgs_terms = do_terms + hpo_terms\n",
    "\n",
    "# Initialize a list to hold the embeddings\n",
    "kgs_embeddings_list = []\n",
    "\n",
    "# For each term in the knowledge graph, generate an embedding\n",
    "for term in tqdm(kgs_terms):\n",
    "    # Here we assume that each term is a string that SapBERT can process\n",
    "    # If the terms are not strings or need pre-processing, you'll need to handle that\n",
    "    embedding = get_embedding(term)\n",
    "    kgs_embeddings_list.append(embedding)\n",
    "\n",
    "# Convert the list of embeddings into a NumPy array for efficient computation\n",
    "kgs_embeddings = np.vstack(kgs_embeddings_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaf75c0fe664c7b8d090fdcde17ae7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'mention_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mention_embedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:17\u001b[0m\n",
      "File \u001b[0;32m/data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/data/user/mikegtr/Conda_Env/nlp2023v2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mention_embedding'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute Recall for Candidate Generation Code\n",
    "X = []  # to hold the feature vectors\n",
    "Y = []  # to hold the labels (1 for correct CUI, 0 for incorrect)\n",
    "\n",
    "# Compute recall\n",
    "correct_predictions = 0\n",
    "total_mentions = len(mention_mapping)\n",
    "\n",
    "# For each mention in the mention_mapping DataFrame\n",
    "for index, row in tqdm(mention_mapping.iterrows()):\n",
    "    mention = row['mention']\n",
    "    correct_cui = row['CUI']\n",
    "\n",
    "    # Convert mention to embedding using a predefined function, such as:\n",
    "    # mention_embedding = convert_to_embedding(mention)\n",
    "    # For simplicity, let's assume the embeddings are part of the DataFrame:\n",
    "    mention_embedding = row['mention_embedding']\n",
    "    \n",
    "    # Double-check the shape of mention_embedding\n",
    "    if mention_embedding.ndim != 2 or mention_embedding.shape[0] != 1:\n",
    "        raise ValueError(f\"Unexpected shape for mention_embedding: {mention_embedding.shape}\")\n",
    "\n",
    "    candidates = getCandidates(mention_embedding, kgs_embeddings, kgs_terms, 3, id_to_cui)\n",
    "    \n",
    "    # Check if the correct CUI is in the candidates\n",
    "    print(f\"Correct CUI: {correct_cui}\")\n",
    "    print(f\"Candidates: {candidates}\")\n",
    "\n",
    "    # Check if the correct CUI is in the candidates\n",
    "    if any(correct_cui == cand[0] for cand in candidates):\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        # Debugging: Print out the mention text when the correct CUI is not found\n",
    "        print(f\"Correct CUI not found for mention: {mention}\")\n",
    "    \n",
    "    # Generate features and labels for the candidates\n",
    "    for candidate in candidates:\n",
    "        # Extract features for the candidate concept\n",
    "        features = getFeatures(mention, candidate)\n",
    "        \n",
    "        # Check if the candidate's CUI is the correct one and assign the label\n",
    "        label = 1 if candidate[0] == correct_cui else 0\n",
    "        \n",
    "        # Append the features and label to the X and Y lists\n",
    "        X.append(features)\n",
    "        Y.append(label)\n",
    "\n",
    "# Calculate the recall\n",
    "recall_at_3 = correct_predictions / total_mentions\n",
    "print(f\"The correct preds: {correct_predictions} and total mentions: {total_mentions}\")\n",
    "print(f'Recall at n=3: {recall_at_3}')\n",
    "\n",
    "# Convert X and Y to the appropriate format for training, such as numpy arrays\n",
    "# This is required for the machine learning ranking algorithm in the next step\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "# Create X (data), Y (label) for ranking algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1c: Random Forest Candidate Ranker and Feature Analysis (10 points)\n",
    "\n",
    " * Split your data into training and testing data and then train scikit-learn's RandomForestClassifier to predict if a candidate node is the correct match. Output a classification report with accuracy.\n",
    " \n",
    " * Use scikit-learn's RandomForestClassifier to compute the relative importance of your features for this algorithm and graph them. Give your features reasonable names so they look nice on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4011\n",
      "\n",
      "    accuracy                           1.00      4011\n",
      "   macro avg       1.00      1.00      1.00      4011\n",
      "weighted avg       1.00      1.00      1.00      4011\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Step 1: Splitting the dataset\n",
    "print(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Training the model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Step 3: Making predictions and evaluating the model\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "# Step 4: Analyzing feature importance\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Assuming you have named your features\n",
    "feature_names = [\"Length of Candidate Concept\", \"Text Similarity\", \"Graph-Based Feature\"]\n",
    "\n",
    "# Step 5: Graphing feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, feature_importances)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance in RandomForest Classifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a (20 points)\n",
    "\n",
    "One of the issues with medical normalization is that training data is sparse, some disease are over-represented, whereas some rare disease have a dictionary entry but few examples in clinical text. Making at least one reference to a paper discussed in class:\n",
    "\n",
    "\n",
    "* Describe how you could use a LLM (like GPT-4) to generate a synthetic corpus for concept normalization to an ontology like the Human Phenotype Ontology described here? Assume you would like to generate synthetic data for concepts not included in typical training data. (10 points)\n",
    "\n",
    "\n",
    "* Propose an evaluation method for your synthetic text generation method. How would you evaluate whether your approach is successfull? (10 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of 2023, transfer learning using large language models such as GPT-4, etc.. is the current best practise for a large number of tasks. There has been speculation in the popular press that these models will function as artificial general intelligences, making domain specific models redundant.\n",
    "\n",
    "* Making references to at least one paper discussed in class, describe performance results indicating that this is not the case. (10 points)\n",
    "\n",
    "* Describe at least 2 benefits of using a domain specific language model that has been fine-tuned on a task,  relative to a model like GPT-4 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp2023v2]",
   "language": "python",
   "name": "conda-env-nlp2023v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
